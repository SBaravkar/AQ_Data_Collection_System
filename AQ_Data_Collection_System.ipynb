{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca07f3a2-153d-4c87-b0e4-bf149e7b969d",
   "metadata": {},
   "source": [
    "### Import Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51716a8a-a376-4863-a1dd-3dde9090756a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, Matern, WhiteKernel, ConstantKernel as C\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import math\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10156745-28df-4919-81c8-6d266176bba7",
   "metadata": {},
   "source": [
    "### Set Params (Execute only once for model re-trainings, otherwise this can be set to empty for other scenarios)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02f46a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_exploit_data = []\n",
    "random_data = []\n",
    "fixed_interval_data = []\n",
    "#Set it true when model retrainings are performed.\n",
    "sampling_flag = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30507cc7",
   "metadata": {},
   "source": [
    "### Model Training (Start after 1st wekk Data Collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8881c1-6523-4124-b1c8-ca37a9efcc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# Global variables\n",
    "num_samples = 2000\n",
    "num_users = 10\n",
    "file_path = r'D:\\AQ\\archive\\CitieSHealth_BCN_DATA_PanelStudy_20220414.csv'\n",
    "train_start_idx = 0\n",
    "N = 42 # Samples per user\n",
    "exploit_thres = 0.3\n",
    "\n",
    "\n",
    "# Load and filter CSV data\n",
    "def load_and_filter_csv(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    columns = ['pm25bcn', 'tmean_24h', 'humi_24h', 'pressure_24h', 'bienestar']\n",
    "    df = df[columns].dropna()\n",
    "    df['bienestar'] = (df['bienestar'] * 10).astype(int)  # Scale 'bienestar'\n",
    "    return df\n",
    "\n",
    "# Preprocess the data\n",
    "def preprocess_data(df):\n",
    "    X = df[['pm25bcn', 'tmean_24h', 'humi_24h', 'pressure_24h']].values  # Features\n",
    "    y = df['bienestar'].values  # Target (mood score)\n",
    "    \n",
    "    # Standardizing the features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    return X_scaled, y, scaler\n",
    "    \n",
    "def train_gaussian_process(X_train, y_train):\n",
    "\n",
    "    # For model re-trainings, past data will be considered as well.\n",
    "    if sampling_flag:\n",
    "        # Use data from explore_exploit_data\n",
    "        X_train = np.concatenate((np.array([item[\"X\"] for item in explore_exploit_data]), X_scaled[train_start_idx:train_start_idx + num_samples]), axis=0)\n",
    "        y_train = np.concatenate((np.array([item[\"y\"] for item in explore_exploit_data]), y[train_start_idx:train_start_idx + num_samples]), axis=0)\n",
    "   \n",
    "    # For other scenarios like changing number of samples or exploit threshold (For this Case execute Set Params Cell)\n",
    "    else:\n",
    "        # Default behavior when sampling_flag is False\n",
    "        X_train = X_scaled[train_start_idx:train_start_idx + num_samples]\n",
    "        y_train = y[train_start_idx:train_start_idx + num_samples]\n",
    "        print(\"False\")\n",
    "    # Define a kernel with an RBF component\n",
    "    kernel = (C(1.0, (1e-3, 1e3)) * RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e2)) +\n",
    "                  C(1.0, (1e-3, 1e3)) * Matern(length_scale=1.0, nu=1.5, length_scale_bounds=(1e-2, 1e2)) +\n",
    "                  WhiteKernel(noise_level=1e-1, noise_level_bounds=(1e-5, 1e1)))\n",
    "    gpr = GaussianProcessRegressor(kernel=kernel, alpha=1e-10, n_restarts_optimizer=10, normalize_y=True)\n",
    "    \n",
    "    # Fit the model\n",
    "    gpr.fit(X_train, y_train)\n",
    "    y_pred, sigma = gpr.predict(X_train, return_std=True)\n",
    "    return gpr, y_pred, sigma\n",
    "\n",
    "# Function to select exploitation samples based on uncertainty threshold\n",
    "def select_exploitation_samples(sigma, exploit_thres, N):\n",
    "    print(len(sigma))\n",
    "    # Calculate the number of samples to exploit based on theta and N\n",
    "    exploitation_count = int(exploit_thres * N)\n",
    "\n",
    "    # Sort the uncertainty (sigma) values in descending order\n",
    "    sorted_sigma = np.sort(sigma)[::-1]\n",
    "    # Select the exploitation samples based on the highest uncertainty\n",
    "    exploitation_threshold = sorted_sigma[exploitation_count - 1]\n",
    "\n",
    "    # Identify the samples that have uncertainty above the threshold\n",
    "    exploitation_samples = np.where(sigma >= exploitation_threshold)[0]\n",
    "\n",
    "    # Return the selected exploitation samples and the threshold\n",
    "    return exploitation_count, exploitation_samples, exploitation_threshold\n",
    "    \n",
    "# Main execution\n",
    "data = load_and_filter_csv(file_path)\n",
    "X_scaled, y, scaler = preprocess_data(data)\n",
    "gpr, y_pred, sigma =  train_gaussian_process(X_scaled, y)\n",
    "exploitation_count, exploitation_samples, exploitation_threshold = select_exploitation_samples(sigma, exploit_thres, N)\n",
    "\n",
    "# Print the selected exploitation samples and threshold\n",
    "print(\"Exploitation Samples Indices:\", exploitation_samples)\n",
    "print(\"Exploitation Threshold:\", exploitation_threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e85433-a421-4fd2-aedf-71016ca945e4",
   "metadata": {},
   "source": [
    "### Consider this as real-time data for num_users (10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d251aaf-4727-4b27-abc7-613b09c7f18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize number of users and number of samples per user\n",
    "num_users = 10\n",
    "\n",
    "# Create a dictionary to store X and y data for each user\n",
    "Data_For_Sampling = {}\n",
    "\n",
    "num_records_per_user = 100  # Number of records to assign to each user\n",
    "\n",
    "for i in range(num_users):\n",
    "    # Calculate the start and end index for each user\n",
    "    start_idx = 2000 + i * num_records_per_user\n",
    "    end_idx = start_idx + num_records_per_user\n",
    "    \n",
    "    # Save data in the dictionary with the user name as the key\n",
    "    Data_For_Sampling[f'User {i+1}'] = {\n",
    "        'X': X_scaled[start_idx:end_idx],\n",
    "        'y': y[start_idx:end_idx]\n",
    "    }\n",
    "\n",
    "print(len(Data_For_Sampling.values()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7ef9bb-b4e0-494c-aa01-1557d33f6513",
   "metadata": {},
   "source": [
    "### Logic where Samples are collected out of real-time data by explore or exploit. The 'max_time_gap' can decide how much gap we need between samples. (Currently Value is set for testing purpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b4d756-ebed-4408-9654-c29df6789049",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initialize exploitation counts and last exploitation time for each user\n",
    "exploite_explore_counts = {\n",
    "    f'User {i+1}': {'exploitation_count': 0, 'exploration_count': 0, 'last_exploitation': None, 'last_exploration': None}\n",
    "    for i in range(len(Data_For_Sampling))\n",
    "}\n",
    "\n",
    "# Variables to store true values. This is currently collected simultaneously from available dataset but in real-time this data will be available later.\n",
    "true_y = []\n",
    "\n",
    "# Interval between consecutive messages for each user\n",
    "max_time_gap = 0.01\n",
    "num_records = len(next(iter(Data_For_Sampling.values()))['X'])\n",
    "print(num_records)\n",
    "for record_idx in range(num_records):  # Loop through all records for each user\n",
    "    current_time = datetime.now()  # Get the current time\n",
    "    for user, data in Data_For_Sampling.items():\n",
    "        # Adjust as per sample requirements (How many samples we need)\n",
    "        if len(explore_exploit_data) >= 250:\n",
    "            break\n",
    "        record_X = data['X'][record_idx]  # Get the X data for this record\n",
    "\n",
    "        # Get the last exploitation time for the user\n",
    "        last_exploitation = exploite_explore_counts[user]['last_exploitation'] \n",
    "        last_exploration = exploite_explore_counts[user]['last_exploration']\n",
    "        \n",
    "        # Predict using the GPR model\n",
    "        _, sigma = gpr.predict([record_X], return_std=True)  # Predict sigma\n",
    "        true_value = data['y'][record_idx]\n",
    "        true_value = int(true_value)\n",
    "\n",
    "        \n",
    "\n",
    "        # Check conditions for exploitation, exploration, or do nothing\n",
    "        if (last_exploitation is None or (current_time - last_exploitation).total_seconds() >= max_time_gap) and \\\n",
    "           (last_exploration is None or (current_time - last_exploration).total_seconds() >= max_time_gap):\n",
    "           \n",
    "            if exploite_explore_counts[user]['exploitation_count'] <= exploitation_count and sigma >= exploitation_threshold:\n",
    "                # Store true values\n",
    "                true_y.append(true_value)\n",
    "                print(f\"Live data {record_idx+1}: {user} - Sigma: {sigma}\")\n",
    "                    \n",
    "                # Update exploitation count and time\n",
    "                exploite_explore_counts[user]['exploitation_count'] += 1\n",
    "                exploite_explore_counts[user]['last_exploitation'] = current_time\n",
    "                \n",
    "                explore_exploit_data.append({\n",
    "                    \"X\": record_X,\n",
    "                    \"y\": true_value\n",
    "                })\n",
    "            else:\n",
    "                if exploite_explore_counts[user]['exploration_count'] <= N - exploitation_count:\n",
    "                    # Store true values\n",
    "                    true_y.append(true_value)\n",
    "                    exploite_explore_counts[user]['exploration_count'] += 1\n",
    "                    exploite_explore_counts[user]['last_exploration'] = current_time\n",
    "                    print(\"Explore\")\n",
    "                    explore_exploit_data.append({\n",
    "                    \"X\": record_X,\n",
    "                    \"y\": true_value,\n",
    "                })\n",
    "        else:\n",
    "            print(\"Do nothing\")\n",
    "        time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5aa18c-4ab6-4068-b9c9-06ae2039cb67",
   "metadata": {},
   "source": [
    "### Testing the accuracy (Mean-Absolute Error) for the collected samples (Explore-Exploit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9688b5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = np.array([data['X'] for data in explore_exploit_data])\n",
    "y_train = np.array([data['y'] for data in explore_exploit_data])\n",
    "\n",
    "# Initialize the MLP Regressor with the requested configuration\n",
    "model = MLPRegressor(hidden_layer_sizes=(64, 64), max_iter=500, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the values\n",
    "y_pred = model.predict(X_train)\n",
    "\n",
    "# Calculate MAE (Mean Absolute Error)\n",
    "mae = mean_absolute_error(y_train, y_pred)\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4775d9-3590-45c4-a644-a4af37f14020",
   "metadata": {},
   "source": [
    "### The data is trained for samples and the live samples are collected randomly and fixed-interval (i.e SMS sending randomly or at fixed-Interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04586f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_and_filter_csv(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    columns = ['pm25bcn', 'tmean_24h', 'humi_24h', 'pressure_24h', 'bienestar']\n",
    "    df = df[columns].dropna()  # Drop rows with missing values\n",
    "    df['bienestar'] = (df['bienestar'] * 10).astype(int)  # Scale 'bienestar'\n",
    "    return df\n",
    "\n",
    "# Preprocess the data\n",
    "def preprocess_data(df):\n",
    "    X = df[['pm25bcn', 'tmean_24h', 'humi_24h', 'pressure_24h']].values  # Features\n",
    "    y = df['bienestar'].values  # Target\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    return X_scaled, y\n",
    "\n",
    "# Train the model\n",
    "def train_model(X_train, y_train):\n",
    "    model = MLPRegressor(hidden_layer_sizes=(64, 64), max_iter=500, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# Evaluate the model\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    return rmse, mae, r2\n",
    "\n",
    "file_path = r'D:\\AQ\\archive\\CitieSHealth_BCN_DATA_PanelStudy_20220414.csv'\n",
    "data = load_and_filter_csv(file_path)\n",
    "# Load your data (replace with your actual data)\n",
    "\n",
    "\n",
    "    \n",
    "if sampling_flag:\n",
    "\n",
    "    # Use sampled data for training and evaluation separately\n",
    "    train_data_random = np.array([entry[\"X\"] for entry in random_data])\n",
    "    train_labels_random = np.array([entry[\"y\"] for entry in random_data])\n",
    "\n",
    "    train_data_fixed = np.array([entry[\"X\"] for entry in fixed_interval_data])\n",
    "    train_labels_fixed = np.array([entry[\"y\"] for entry in fixed_interval_data])\n",
    "\n",
    "    random_indices = np.random.choice(range(2000, 3000), size=1000, replace=False)\n",
    "    X_train_random, y_train_random = X_scaled[random_indices], y[random_indices]\n",
    "    # Train and evaluate for random selection\n",
    "    X_combined = np.concatenate([X_scaled[random_indices], train_data_random], axis=0)\n",
    "    y_combined = np.concatenate([y[random_indices], train_labels_random], axis=0)\n",
    "\n",
    "    # Train the model\n",
    "    model_random = train_model(X_combined, y_combined)\n",
    "    rmse_random, mae_random, r2_random = evaluate_model(model_random, X_train_random, y_train_random)\n",
    "    print(f\"Random Data Evaluation:\\nRMSE: {rmse_random}, MAE: {mae_random}, R²: {r2_random}\")\n",
    "\n",
    "    #interval_indices = np.arange(2000, 3000, 2)  # Select records with fixed intervals\n",
    "    interval_indices = np.linspace(0, 1000 - 1, 1000, dtype=int)\n",
    "    X_train_interval, y_train_interval = X_scaled[interval_indices], y[interval_indices]\n",
    "    # Train and evaluate for fixed interval selection\n",
    "    model_interval = train_model(np.concatenate([X_scaled[interval_indices], train_data_fixed], axis=0),\n",
    "                             np.concatenate([y[interval_indices], train_labels_fixed], axis=0))\n",
    "    rmse_interval, mae_interval, r2_interval = evaluate_model(model_interval, X_train_interval, y_train_interval)\n",
    "    print(f\"Fixed Interval Data Evaluation:\\nRMSE: {rmse_interval}, MAE: {rmse_interval}, R²: {r2_interval}\")\n",
    "\n",
    "else:\n",
    "    # Preprocess the data\n",
    "    X_scaled, y = preprocess_data(data)\n",
    "\n",
    "    # Step 1: Train with records\n",
    "    train_data = X_scaled[:2000]  \n",
    "    train_labels = y[:2000]\n",
    "\n",
    "    # Step 2: Select random samples from for testing\n",
    "    random_indices = np.random.choice(range(2000, 3000), size=250, replace=False)\n",
    "    print(len(random_indices))\n",
    "    X_train_random, y_train_random = X_scaled[random_indices], y[random_indices]\n",
    "    for i in range(len(X_train_random)):\n",
    "        random_data.append({\"X\": X_train_random[i], \"y\": y_train_random[i]})\n",
    "\n",
    "    # Step 3: Select samples with a fixed interval for testing\n",
    "   # interval_indices = np.arange(2000, 3000, 1.5)  # Select records with fixed intervals\n",
    "    interval_indices = np.linspace(0, 1000 - 1, 250, dtype=int)\n",
    "\n",
    "    print(len(interval_indices))\n",
    "    X_train_interval, y_train_interval = X_scaled[interval_indices], y[interval_indices]\n",
    "    for i in range(len(X_train_interval)):\n",
    "        fixed_interval_data.append({\"X\": X_train_interval[i], \"y\": y_train_interval[i]})\n",
    "    # Train the model and evaluate for random selection\n",
    "    model_random = train_model(train_data, train_labels)\n",
    "    rmse_random, mae_random, r2_random = evaluate_model(model_random, X_train_random, y_train_random)\n",
    "    print(f\"Random Split Evaluation:\\nRMSE: {rmse_random}, MAE: {mae_random}, R²: {r2_random}\")\n",
    "\n",
    "    # Train the model and evaluate for fixed interval selection\n",
    "    model_interval = train_model(train_data, train_labels)\n",
    "    rmse_interval, mae_interval, r2_interval = evaluate_model(model_interval, X_train_interval, y_train_interval)\n",
    "    print(f\"Fixed Interval Split Evaluation:\\nRMSE: {rmse_interval}, MAE: {rmse_interval}, R²: {r2_interval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bedf5e-a6c9-4e6a-b848-4deb2d5d7eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set True when required for re-training\n",
    "sampling_flag = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d4ba02-f650-400e-acef-ff8d4fdc3711",
   "metadata": {},
   "source": [
    "### Testing the MAE by setting different 'exploit_thres' param in Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e166cab-3a0a-4818-8921-3f42ab485ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data for the graph\n",
    "x = ['10%' , '30%', '50%', '70%', '90%']\n",
    "accuracies = {\n",
    "    'E&E': [12.76, 11.38, 12.98, 12.62, 12.35]\n",
    "}\n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize=(4, 4))\n",
    "for algo, values in accuracies.items():\n",
    "    plt.plot(x, values, marker='o')\n",
    "\n",
    "# Adding titles and labels\n",
    "plt.title(\"Explore-Exploit Distribution\", fontsize=16)\n",
    "plt.xlabel(\"Explore/Exploit Ratios\", fontsize=12)\n",
    "plt.ylabel(\"MAE Values\", fontsize=12)\n",
    "plt.ylim(11.25, 13.00)\n",
    "plt.tick_params(axis='both', labelsize=11)\n",
    "\n",
    "plt.grid(True)\n",
    "\n",
    "# Save the plot as PDF\n",
    "plt.savefig(r'D:\\AQ\\E&E_Distribution.pdf', format='pdf')\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d218470-07ab-4f2f-89d7-b228341843ab",
   "metadata": {},
   "source": [
    "### Testing the MAE for Model retrainings across all Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb73a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for the graph\n",
    "algorithms = ['E&E', 'Random', 'Fixed Interval']\n",
    "x = ['Initial Phase', 'Round 1', 'Round 2', 'Round 3']\n",
    "rmse_values = {\n",
    "    'E&E': [12.13, 11.38, 11.13, 9.94],\n",
    "    'Random': [13.01, 12.51, 11.83, 10.96],\n",
    "    'Fixed': [16.02, 15.37, 14.27, 12.43]\n",
    "}\n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize=(4, 4))\n",
    "for algo, values in rmse_values.items():\n",
    "    plt.plot(x, values, marker='o', label=algo)\n",
    "\n",
    "# Adding titles and labels\n",
    "plt.title(\"MAE Comparison Across Algorithms\")\n",
    "plt.xlabel(\"Model Retrain Rounds\")\n",
    "plt.ylabel(\"MAE Values\")\n",
    "plt.ylim(8, 18)\n",
    "\n",
    "plt.legend(title=\"Algorithms\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.savefig(r'D:\\AQ\\MAE_ChangesOverTime.pdf', format='pdf')\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51eecfeb-3004-45ce-bd34-ed48f792e794",
   "metadata": {},
   "source": [
    "### Testing the MAE by changing count in 'explore_exploit_data', 'random_data' and 'fixed_interval_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbe5434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for the graph\n",
    "algorithms = ['E&E', 'Random', 'Fixed Interval']\n",
    "x = ['250', '500', '750', '2000']\n",
    "rmse_values = {\n",
    "    'E&E': [12.13, 11.82, 11.75, 11.44],\n",
    "    'Random': [13.04, 12.81, 12.51, 11.44],\n",
    "    'Fixed': [16.02, 16.02, 15.53, 11.44]\n",
    "}\n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize=(4, 4))\n",
    "for algo, values in rmse_values.items():\n",
    "    plt.plot(x, values, marker='o', label=algo)\n",
    "\n",
    "# Adding titles and labels\n",
    "plt.title(\"MAE Comparison Across Algorithms\")\n",
    "plt.xlabel(\"Initial Number of Samples (w/o Model Retraining)\")\n",
    "plt.ylabel(\"MAE Values\")\n",
    "plt.ylim(10, 18)\n",
    "\n",
    "plt.legend(title=\"Algorithms\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.savefig(r'D:\\AQ\\MAE_SampleSizes.pdf', format='pdf')\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e090205-da15-4cf5-aaeb-a89769662442",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Load and filter CSV data\n",
    "def load_and_filter_csv(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    columns = ['pm25bcn', 'tmean_24h', 'humi_24h', 'pressure_24h', 'bienestar']\n",
    "    df = df[columns].dropna()\n",
    "    df['bienestar'] = (df['bienestar'] * 10).astype(int)  # Scale 'bienestar'\n",
    "    return df\n",
    "\n",
    "# Preprocess the data\n",
    "def preprocess_data(df):\n",
    "    X = df[['pm25bcn', 'tmean_24h', 'humi_24h', 'pressure_24h']].values  # Features\n",
    "    y = df['bienestar'].values  # Target (mood score)\n",
    "    \n",
    "    # Standardizing the features\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    return X_scaled, y, scaler\n",
    "\n",
    "# Train and test the MLPRegressor\n",
    "def train_and_evaluate_model(X_train, y_train, X_test, y_test):\n",
    "    # Define the MLPRegressor model\n",
    "    model = MLPRegressor(hidden_layer_sizes=(64, 64), max_iter=500, random_state=42)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate Mean Absolute Error (MAE)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    return model, mae\n",
    "\n",
    "# Main execution\n",
    "file_path = r'D:\\AQ\\archive\\CitieSHealth_BCN_DATA_PanelStudy_20220414.csv'\n",
    "df = load_and_filter_csv(file_path)\n",
    "\n",
    "# Split the data\n",
    "X, y, scaler = preprocess_data(df)\n",
    "X_train, y_train = X[:2000], y[:2000]  # First 2000 records for training\n",
    "X_test, y_test = X[2000:3000], y[2000:3000]  # Last 1000 records for testing\n",
    "\n",
    "# Train and evaluate the model\n",
    "model, mae = train_and_evaluate_model(X_train, y_train, X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a33e839-3687-4121-9cc4-d0775e2183d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dbae79-8232-4c34-aba8-ab1aa39fa9d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
